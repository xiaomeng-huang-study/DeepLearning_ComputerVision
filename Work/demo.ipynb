{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import relevant libraries for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, auc, roc_curve\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import v2, ToTensor, Normalize\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.transforms import Grayscale\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"ResNet18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 8\n",
    "NUM_WORKERS = 0  # dont change this inside of the jupyter notebook (it will crash)\n",
    "SEED = 42\n",
    "\n",
    "MODEL_SAVE_PATH = f'./models/{arch}/best_model.pth'\n",
    "\n",
    "# Classes of images in test dataset\n",
    "CLASSES = ['defective', 'ok']\n",
    "N_CLASSES = len(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size for ResNet\n",
    "img_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26e98dd2950>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"active device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Transforms\n",
    "transform = v2.Compose([\n",
    "    ToTensor(),\n",
    "    v2.Resize(img_size, interpolation=v2.InterpolationMode.NEAREST),\n",
    "    Grayscale(num_output_channels= 1),\n",
    "    Normalize([0.5], [0.5]),\n",
    "])\n",
    "\n",
    "def target_transform(x):\n",
    "    return F.one_hot(torch.LongTensor([x]), N_CLASSES)[0].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, num_classes= 2, input_channels= 1):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        \n",
    "        # load the pre-trained ResNet model\n",
    "        self.base_model = resnet18(weights= ResNet18_Weights.DEFAULT)\n",
    "        \n",
    "        # change the input channels of the model\n",
    "        self.base_model.conv1 = nn.Conv2d(\n",
    "            input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
    "        )\n",
    "        \n",
    "        # # Freeze all layers except the last one\n",
    "        # for param in self.base_model.parameters():\n",
    "        #     param.requires_grad = False\n",
    "        \n",
    "        # change the output layer of the model\n",
    "        self.base_model.fc = nn.Linear(self.base_model.fc.in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomResNet(num_classes= N_CLASSES, input_channels= 1)\n",
    "\n",
    "model = torch.load(MODEL_SAVE_PATH, weights_only= False, map_location= device)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(image_path):\n",
    "    # Load and transform the image\n",
    "    image = Image.open(image_path)\n",
    "    input = transform(image).unsqueeze(0).to(device)  # Add batch dimension and move to the device\n",
    "\n",
    "    # Perform prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input)\n",
    "        probabilities = torch.softmax(output.squeeze(), dim=0)  # Convert logits to probabilities\n",
    "        predicted_class = torch.argmax(probabilities).item()  # Get the predicted class index\n",
    "\n",
    "    # Print the prediction result and probabilities\n",
    "    print(f\"Predicted Class: {CLASSES[predicted_class]}\")\n",
    "    for i, prob in enumerate(probabilities):\n",
    "        print(f\"Class: {CLASSES[i]}, Probability: {prob.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: ok\n",
      "Class: defective, Probability: 0.0000\n",
      "Class: ok, Probability: 1.0000\n"
     ]
    }
   ],
   "source": [
    "image_path = './demo/demo_1.jpeg'\n",
    "predict_single_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: defective\n",
      "Class: defective, Probability: 1.0000\n",
      "Class: ok, Probability: 0.0000\n"
     ]
    }
   ],
   "source": [
    "image_path = './demo/demo_2.jpeg'\n",
    "predict_single_image(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_dlacv_projekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
